{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898a078b",
   "metadata": {
    "cellId": "xzel6gwtm99goaxrut0z4f",
    "execution_id": "8c22a650-1cde-482b-b6a8-a0170d195650"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ae4b5a3b",
   "metadata": {
    "cellId": "5xx87cw1rhqqevyb116ii"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# %pip install transformers==4.27.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03a2ef",
   "metadata": {
    "cellId": "7nyizx8tkfwro932vygar9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a38bc596",
   "metadata": {
    "cellId": "vsstuvpke8ldcob8rrg817"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "!rm -rf .cache/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8cd38854",
   "metadata": {
    "cellId": "ty0iulp6q0ed7qwz3tv61"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af170835e11420eb3a11a943e882ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)okenizer_config.json'), FloatProgress(value=0.0, max=749.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c3d40eb7b9468d84cb8489c1d16134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)olve/main/vocab.json'), FloatProgress(value=0.0, max=1612610.0), HTM…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34865899532495e84db7d2d6f078877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)olve/main/merges.txt'), FloatProgress(value=0.0, max=1270963.0), HTM…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d41098307d41958334a905f9d32b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading tokenizer.json'), FloatProgress(value=0.0, max=3737183.0), HTML(value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbb9960975d44cdb59542e6812b64de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)in/added_tokens.json'), FloatProgress(value=0.0, max=29.0), HTML(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122ad50dfffc479caea6f560058df97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)cial_tokens_map.json'), FloatProgress(value=0.0, max=118.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740eac8fee684cdfadddda9853341dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)lve/main/config.json'), FloatProgress(value=0.0, max=947.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25805cb9f9ca4ac6bc91fe9f6d82ee67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading pytorch_model.bin'), FloatProgress(value=0.0, max=3141980445.0), HTML(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce924c6799d44a629a3e367905a21976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)neration_config.json'), FloatProgress(value=0.0, max=225.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "model_name = GUSEV_LARGE_TURBO\n",
    "cache_dir = '.cache'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e378af87",
   "metadata": {
    "cellId": "66tht6y54jjcrc7aztl2rb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer.pad_token = '<pad>'\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "df75a7ee",
   "metadata": {
    "cellId": "4zfvgm315o34n588vqk2cc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=32,\n",
    "    do_sample=True,\n",
    "    \n",
    "    top_p=0.95,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.2,\n",
    "\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "76f465a0",
   "metadata": {
    "cellId": "ljqy7zqhwrdrt3uxxwkc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Когда-то я был таким же, как ты. Я любил свою работу и мечтал о том дне, когда смогу уйти на пенсию. Но однажды я встретил своего'},\n",
       " {'generated_text': 'Имя: Андрей Имя: Андрей, привет! Как дела? Я тут недавно узнал о твоем проекте. Расскажи мне все подробности и я сделаю тебе предложение!'},\n",
       " {'generated_text': 'у меня была идея, что я могу сделать для своего города. Я начал с того, чтобы найти людей, которые хотели бы работать в моем городе и помочь им'},\n",
       " {'generated_text': 'в парке, где много деревьев и цветов, я увидел прекрасную картину. На скамейке сидела девушка с книгой в руках. Вокруг нее были разбросаны цветы и листья.'},\n",
       " {'generated_text': 'я шел по улице и увидел женщину, которая сидела на скамейке. Я подошел к ней и спросил: \"Что случилось?\" Она ответила мне: \"Я потеряла своего'}]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "prompt = '''\n",
    "Однажды\n",
    "'''\n",
    "output = generator(\n",
    "    prompt,\n",
    "    generation_config=generation_config,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=5\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8e028",
   "metadata": {
    "cellId": "6a67un8s3rqh8rtv0f0zzc",
    "execution_id": "ff19e2d9-1414-4251-895f-96b36a3b1dfd"
   },
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b85fa88c",
   "metadata": {
    "cellId": "1emsnirtl6m10wuvlk2425"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'84_large_turbo_terra'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "task = TERRA\n",
    "count = len(list(Path('evals').glob('*.jsonl')))\n",
    "eval = f'{count + 1}_large_turbo_{task}'\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f17909d9",
   "metadata": {
    "cellId": "l8ejsvbu0ny0o7vjlgr3"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "lines = read_lines(f'tasks/{task}.jsonl')\n",
    "task_items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2131818f",
   "metadata": {
    "cellId": "lno0o4fed7bqtpxnysgtya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение.\n",
      "Ответь коротко: да или нет. Если не уверен, выбери наиболее вероятный ответ.\n",
      "---\n",
      "Текст: Трижды он был привлечён судебным приставом к административной ответственности по ст. 17.15 КоАП РФ за неисполнение содержащихся в исполнительном документе требований неимущественного характера. Так как срок для добровольного исполнения истёк, пристрой снесли принудительно.\n",
      "Утверждение: Пристрой был снесен.\n",
      "Верно: Да\n",
      "---\n",
      "Текст: Для молодого организма это не прошло бесследно. Резкое токсическое воздействие этанола привело к смерти парня. Его тело обнаружила бабушка, которая вернулась на следующий день.\n",
      "Утверждение: Молодой организм стал сильнее от этанола.\n",
      "Верно: Нет\n",
      "---\n",
      "Текст: В зарубежной практике примеров подобной нормы, по его мнению, не встречается. В мировой практике акционерное соглашение дополняет или замещает некоторые элементы учредительных документов. Делается это в том числе для того, чтобы сохранить некоторые положения соглашений конфиденциальными, поскольку учредительные документы доступны широкому кругу лиц.\n",
      "Утверждение: В мировой практике акционерное соглашение только дополняет некоторые элементы учредительных документов.\n",
      "Верно: \n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "prompts = [\n",
    "    TASK_PROMPTS[task](_)\n",
    "    for _ in task_items\n",
    "]\n",
    "prompt = random.choice(prompts)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6f799730",
   "metadata": {
    "cellId": "xovp26g48esf50z78rcglu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '^\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'},\n",
       " {'generated_text': '\\nДа\\x00\\x00\\x03\\x02�‘s\\x1d¿\\x07� │\\n[id285'},\n",
       " {'generated_text': '\\nНет\\x00\\x1d\\x00\\x03�\\x00\\x0b�\\x00!\\x00\\x03�\\x00!\\x03�\\x00!\\x16�'},\n",
       " {'generated_text': '\\nНет\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'}]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "generator(\n",
    "    prompt,\n",
    "    generation_config=generation_config,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "87a414b1",
   "metadata": {
    "cellId": "djv8al582rtjtkl01pnyl"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "output = generator(\n",
    "    prompts,\n",
    "    generation_config=generation_config,\n",
    "    return_full_text=False,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "41850b52",
   "metadata": {
    "cellId": "at63u89y7mh37alb32g2ii"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': '\\nНет\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'}],\n",
       " [{'generated_text': '\\nНет\\x00\\x00\\x03\\x00\\x03\\x02��\\x00\\x0b��\\x00\\x0f\\x00\\x1d\\x00̃�'}],\n",
       " [{'generated_text': '````````````````````````````````'}]]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "random.sample(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ce4e258e",
   "metadata": {
    "cellId": "q2arwkcei0hpa5kr1nyc1f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "eval_items = []\n",
    "for task_item, response_item in zip(task_items, output):\n",
    "    response = response_item[0]['generated_text']\n",
    "\n",
    "    eval_items.append({\n",
    "        'id': task_item['id'],\n",
    "        'response': response\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e370ad60",
   "metadata": {
    "cellId": "ndc2mobemdhs0f4pw0dt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43548387096774194, 38)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "id_targets = {\n",
    "    _['id']: _['label']\n",
    "    for _ in task_items\n",
    "}\n",
    "norm_response = NORM_RESPONSES[task]\n",
    "id_preds = {\n",
    "    _['id']: norm_response(_['response'])\n",
    "    for _ in eval_items\n",
    "}\n",
    "acc_score(id_targets, id_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "35bb53b6",
   "metadata": {
    "cellId": "d1jtl9p66je06hrq46d5q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "lines = format_jsonl(eval_items)\n",
    "write_lines(f'evals/{eval}.jsonl', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "26c3e167",
   "metadata": {
    "cellId": "s9cm7zvg5cxh0tq06mqxh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for task in TASKS[1:]:\n",
    "    count = len(list(Path('evals').glob('*.jsonl')))\n",
    "    eval = f'{count + 1}_large_turbo_{task}'\n",
    "\n",
    "    lines = read_lines(f'tasks/{task}.jsonl')\n",
    "    task_items = list(parse_jsonl(lines))\n",
    "    \n",
    "    prompts = [\n",
    "        TASK_PROMPTS[task](_)\n",
    "        for _ in task_items\n",
    "    ]\n",
    "    \n",
    "    output = generator(\n",
    "        prompts,\n",
    "        generation_config=generation_config,\n",
    "        return_full_text=False,\n",
    "        batch_size=8\n",
    "    )\n",
    "    \n",
    "    eval_items = []\n",
    "    for task_item, response_item in zip(task_items, output):\n",
    "        response = response_item[0]['generated_text']\n",
    "        eval_items.append({\n",
    "            'id': task_item['id'],\n",
    "            'response': response\n",
    "        })\n",
    "    \n",
    "    lines = format_jsonl(eval_items)\n",
    "    write_lines(f'evals/{eval}.jsonl', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe17ad",
   "metadata": {
    "cellId": "xba5lt3iwumqgts60rp90r"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "abc08afa-8e53-42c4-ac27-342f8bd0759b",
  "notebookPath": "rulm-eval/datasphere.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
