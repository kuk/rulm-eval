{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f68547e",
   "metadata": {
    "cellId": "xzel6gwtm99goaxrut0z4f",
    "execution_id": "8c22a650-1cde-482b-b6a8-a0170d195650"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857bc4e4",
   "metadata": {
    "cellId": "5xx87cw1rhqqevyb116ii"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# %pip install transformers==4.27.1\n",
    "# %pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a916b2ae",
   "metadata": {
    "cellId": "7nyizx8tkfwro932vygar9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 17 09:30:17 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:8C:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "60bdfdda",
   "metadata": {
    "cellId": "vsstuvpke8ldcob8rrg817"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "!rm -rf .cache/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dd0c8e",
   "metadata": {
    "cellId": "ty0iulp6q0ed7qwz3tv61"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583bab7014ac4b689132123d54f7a642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)okenizer_config.json'), FloatProgress(value=0.0, max=246.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd73d5d085244069bf7552b4a2f5e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading tokenizer.json'), FloatProgress(value=0.0, max=14500443.0), HTML(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fc04d013b84c31832b0fd9fd591b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)cial_tokens_map.json'), FloatProgress(value=0.0, max=85.0), HTML(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c8df2421194000887236c5bde863ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading (…)lve/main/config.json'), FloatProgress(value=0.0, max=920.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147448e1b1cc456381c4bfd09a0a08d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading pytorch_model.bin'), FloatProgress(value=0.0, max=3444858091.0), HTML(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "model_name = BLOOM_RU\n",
    "cache_dir = '.cache'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe2d423",
   "metadata": {
    "cellId": "66tht6y54jjcrc7aztl2rb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer.pad_token = '<pad>'\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411bcd99",
   "metadata": {
    "cellId": "k22gw1vpxgurrqxin48ve"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    max_new_tokens=32,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4c8a4b",
   "metadata": {
    "cellId": "ljqy7zqhwrdrt3uxxwkc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'В одной из улиц Саратова около восьми часов ночи сгорела продажа. О'},\n",
       " {'generated_text': 'Обучением плаванию, тренировками физической подготовки. Трениров'},\n",
       " {'generated_text': 'световые специалисты на основании обратных гласит, что и как и с гряз'},\n",
       " {'generated_text': 'Как образование может влиять на психику человека? Казахстанские ученые у'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "prompt = '''\n",
    "Однажды\n",
    "'''\n",
    "output = generator(\n",
    "    prompt,\n",
    "    generation_config=generation_config,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=4\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c0e58c",
   "metadata": {
    "cellId": "6a67un8s3rqh8rtv0f0zzc",
    "execution_id": "ff19e2d9-1414-4251-895f-96b36a3b1dfd"
   },
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988ec3b1",
   "metadata": {
    "cellId": "1emsnirtl6m10wuvlk2425"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66_bloom_ru_terra'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "task = TERRA\n",
    "count = len(list(Path('evals').glob('*.jsonl')))\n",
    "eval = f'{count + 1}_bloom_ru_{task}'\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b97265",
   "metadata": {
    "cellId": "l8ejsvbu0ny0o7vjlgr3"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "lines = read_lines(f'tasks/{task}.jsonl')\n",
    "task_items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da79e2a4",
   "metadata": {
    "cellId": "lno0o4fed7bqtpxnysgtya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение.\n",
      "Ответь коротко: да или нет. Если не уверен, выбери наиболее вероятный ответ.\n",
      "---\n",
      "Текст: Трижды он был привлечён судебным приставом к административной ответственности по ст. 17.15 КоАП РФ за неисполнение содержащихся в исполнительном документе требований неимущественного характера. Так как срок для добровольного исполнения истёк, пристрой снесли принудительно.\n",
      "Утверждение: Пристрой был снесен.\n",
      "Верно: Да\n",
      "---\n",
      "Текст: Для молодого организма это не прошло бесследно. Резкое токсическое воздействие этанола привело к смерти парня. Его тело обнаружила бабушка, которая вернулась на следующий день.\n",
      "Утверждение: Молодой организм стал сильнее от этанола.\n",
      "Верно: Нет\n",
      "---\n",
      "Текст: Я давно хотела слепить снежный мотоцикл, но вот мы только собрались, примерились к этой куче, а я глянула и поняла, что вижу там только Будду. Доброго такого, пузатого, довольного и умиротворенного, - рассказывает Дарья. - Пока делали, несколько раз приходилось объяснять соседям, что это не развратная женщина, потому что начали с ног.\n",
      "Утверждение: Дарья хотела слепить из снега мотоцикл, а слепила Будду.\n",
      "Верно: \n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "prompts = [\n",
    "    TASK_PROMPTS[task](_)\n",
    "    for _ in task_items\n",
    "]\n",
    "prompt = random.choice(prompts)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440d40e2",
   "metadata": {
    "cellId": "xovp26g48esf50z78rcglu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'рылеет стройная шар. Но спровадили человека, охватил всех и тут'},\n",
       " {'generated_text': 'рыбак не только привлекает внимание взрослых, но по-прежнему держит в'},\n",
       " {'generated_text': 'юноша, я знаю, но прожил ее совсем не мало, поэтому Будда и с'},\n",
       " {'generated_text': 'рыжей снежной брат малон, а может, и это что пошло с добрыми друзь'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "generator(\n",
    "    prompt,\n",
    "    generation_config=generation_config,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45040efd",
   "metadata": {
    "cellId": "djv8al582rtjtkl01pnyl"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "output = generator(\n",
    "    prompts,\n",
    "    generation_config=generation_config,\n",
    "    return_full_text=False,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558f96d5",
   "metadata": {
    "cellId": "at63u89y7mh37alb32g2ii"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': 'юридически не вызывает сомнения тот факт, что акционерное общество я'}],\n",
       " [{'generated_text': 'риск ведь есть определённый. Например, на территории Крыма есть о'}],\n",
       " [{'generated_text': 'рыбка, она чем остается заячьим защитником? Если сыпать зубряку'}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "random.sample(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374da521",
   "metadata": {
    "cellId": "q2arwkcei0hpa5kr1nyc1f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "eval_items = []\n",
    "for task_item, response_item in zip(task_items, output):\n",
    "    response = response_item[0]['generated_text']\n",
    "\n",
    "    eval_items.append({\n",
    "        'id': task_item['id'],\n",
    "        'response': response\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b30bb080",
   "metadata": {
    "cellId": "ndc2mobemdhs0f4pw0dt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4090909090909091, 78)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%run -n main.py\n",
    "id_targets = {\n",
    "    _['id']: _['label']\n",
    "    for _ in task_items\n",
    "}\n",
    "norm_response = NORM_RESPONSES[task]\n",
    "id_preds = {\n",
    "    _['id']: norm_response(_['response'])\n",
    "    for _ in eval_items\n",
    "}\n",
    "acc_score(id_targets, id_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe6efee8",
   "metadata": {
    "cellId": "d1jtl9p66je06hrq46d5q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "lines = format_jsonl(eval_items)\n",
    "write_lines(f'evals/{eval}.jsonl', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222c6200",
   "metadata": {
    "cellId": "s9cm7zvg5cxh0tq06mqxh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for task in TASKS[1:]:\n",
    "    count = len(list(Path('evals').glob('*.jsonl')))\n",
    "    eval = f'{count + 1}_bloom_ru_{task}'\n",
    "\n",
    "    lines = read_lines(f'tasks/{task}.jsonl')\n",
    "    task_items = list(parse_jsonl(lines))\n",
    "    \n",
    "    prompts = [\n",
    "        TASK_PROMPTS[task](_)\n",
    "        for _ in task_items\n",
    "    ]\n",
    "    \n",
    "    output = generator(\n",
    "        prompts,\n",
    "        generation_config=generation_config,\n",
    "        return_full_text=False,\n",
    "        batch_size=4\n",
    "    )\n",
    "    \n",
    "    eval_items = []\n",
    "    for task_item, response_item in zip(task_items, output):\n",
    "        response = response_item[0]['generated_text']\n",
    "        eval_items.append({\n",
    "            'id': task_item['id'],\n",
    "            'response': response\n",
    "        })\n",
    "    \n",
    "    lines = format_jsonl(eval_items)\n",
    "    write_lines(f'evals/{eval}.jsonl', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c8bd2",
   "metadata": {
    "cellId": "xba5lt3iwumqgts60rp90r"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "abc08afa-8e53-42c4-ac27-342f8bd0759b",
  "notebookPath": "rulm-eval/datasphere.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
