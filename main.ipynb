{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6c78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines(DOTENV_PATH)\n",
    "pairs = parse_dotenv(lines)\n",
    "os.environ.update(pairs)\n",
    "%run -n main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2b66c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc2f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ac4b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'data/rsg/TERRa/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32279ea0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['label'] == 'entailment'], 50)\n",
    "    + random.sample([_ for _ in items if _['label'] == 'not_entailment'], 50)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c871c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/terra.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be69595",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## danetqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c88ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'data/rsg/DaNetQA/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b3943",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['label'] is True], 50)\n",
    "    + random.sample([_ for _ in items if _['label'] is False], 50)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d09be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/danetqa.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92322f33",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248250c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'data/rsg/PARus/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787ce32",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.seed()\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['question'] == 'effect'], 48)\n",
    "    + random.sample([_ for _ in items if _['question'] == 'cause'], 52)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1d2a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/parus.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54ac4c",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "976a8022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines('tasks/danetqa.jsonl')\n",
    "task_items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cb6136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_ids = {}\n",
    "eval_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72406cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = read_lines('evals/05_turbo_danetqa.jsonl')\n",
    "items = parse_jsonl(lines)\n",
    "cache_ids = {_['id'] for _ in items}\n",
    "len(cache_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19d3a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [05:08<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "%run -n main.py\n",
    "for task_item in log_progress([_ for _ in task_items if _['id'] not in cache_ids]):\n",
    "    prompt = danetqa_prompt(task_item)\n",
    "    response = join_tokens(openai_chat_completions_stream(prompt, model=GPT_35_TURBO_0301))\n",
    "    eval_items.append({\n",
    "        'id': task_item['id'],\n",
    "        'response': response\n",
    "    })\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5ae5d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 270, 'response': 'Yes'},\n",
       " {'id': 734,\n",
       "  'response': 'No (but the passage does not provide evidence that it is not a myth, it describes the reality of political repression in the Soviet Union)'},\n",
       " {'id': 219,\n",
       "  'response': 'Most probable answer: No (as the passage states that liquid water cannot exist stably on Mars currently, although it may have been different in the past)'},\n",
       " {'id': 124, 'response': 'It is unclear from the passage.'},\n",
       " {'id': 377, 'response': 'No'},\n",
       " {'id': 66, 'response': 'Yes'},\n",
       " {'id': 817, 'response': 'Most probable answer: Yes'},\n",
       " {'id': 343,\n",
       "  'response': 'Probable answer: Yes (since the passage mentions a character named Jack Dawson in the movie about the Titanic, but it is not explicitly stated whether he was a real person or not)'},\n",
       " {'id': 732, 'response': 'No'},\n",
       " {'id': 289, 'response': 'No'}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0121e8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, True, False, False, True, True, False, False]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_['label'] for _ in task_items[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "910137d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(eval_items)\n",
    "write_lines('evals/05_turbo_danetqa.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0e5a5",
   "metadata": {},
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa659c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text-davinci-003', 'terra', 0.91),\n",
       " ('text-davinci-003', 'danetqa', 0.79),\n",
       " ('text-davinci-003', 'parus', 0.93),\n",
       " ('gpt-3.5-turbo-0301', 'parus', 0.9130434782608695),\n",
       " ('gpt-3.5-turbo-0301', 'danetqa', 0.8350515463917526)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -n main.py\n",
    "model_task_evals = [\n",
    "    (TEXT_DAVINCHI_003, TERRA, '01_davinci_terra'),\n",
    "    (TEXT_DAVINCHI_003, DANETQA, '02_davinci_danetqa'),\n",
    "    (TEXT_DAVINCHI_003, PARUS, '03_davinci_parus'),\n",
    "    (GPT_35_TURBO_0301, PARUS, '04_turbo_parus'),\n",
    "    (GPT_35_TURBO_0301, DANETQA, '05_turbo_danetqa'),\n",
    "]\n",
    "data = []\n",
    "for model, task, eval in model_task_evals:\n",
    "    lines = read_lines(f'tasks/{task}.jsonl')\n",
    "    id_targets = {\n",
    "        _['id']: _['label']\n",
    "        for _ in parse_jsonl(lines)\n",
    "    }\n",
    "    \n",
    "    lines = read_lines(f'evals/{eval}.jsonl')\n",
    "    norm_response = NORM_RESPONSE[task]\n",
    "    id_preds = {\n",
    "        _['id']: norm_response(_['response'])\n",
    "        for _ in parse_jsonl(lines)\n",
    "    }\n",
    "    score = acc_score(id_targets, id_preds)\n",
    "    data.append((model, task, score))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba976fc",
   "metadata": {},
   "source": [
    "# explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96f5a956",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Я вдавил свою руку во влажный цемент.',\n",
       " 'choice1': 'Отпечатки моих рук застыли на поверхности цемента.',\n",
       " 'choice2': 'В цементе появились трещины.',\n",
       " 'question': 'effect',\n",
       " 'label': 0,\n",
       " 'id': 49}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Женщина уволилась с должности.',\n",
       " 'choice1': 'Она хотела занять руководящую должность в фирме.',\n",
       " 'choice2': 'Она считала, что её начальники вели себя неэтично.',\n",
       " 'question': 'cause',\n",
       " 'label': 1,\n",
       " 'id': 13}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Супруги были рады видеть друг друга.',\n",
       " 'choice1': 'Они поцеловались.',\n",
       " 'choice2': 'Они отдохнули.',\n",
       " 'question': 'effect',\n",
       " 'label': 0,\n",
       " 'id': 69}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Детектив обнаружил неувязку в деле.',\n",
       " 'choice1': 'Он окончательно сформулировал свою версию.',\n",
       " 'choice2': 'Она разрушила его версию.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 52}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Женщина была в плохом настроении.',\n",
       " 'choice1': 'Она вежливо общалась с подругой.',\n",
       " 'choice2': 'Она попросила подругу оставить её в покое.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 99}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Женщина прогнала детей со своей территории.',\n",
       " 'choice1': 'Дети попали мячом в её двор.',\n",
       " 'choice2': 'Дети топтались по её саду.',\n",
       " 'question': 'cause',\n",
       " 'label': 1,\n",
       " 'id': 16}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Девочка отказывалась есть овощи.',\n",
       " 'choice1': 'Её отец сказал ей выпить молока.',\n",
       " 'choice2': 'Её отец оставил её без сладкого.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 28}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Студент спешил добраться до школы вовремя.',\n",
       " 'choice1': 'Он забыл свою домашнюю работу дома.',\n",
       " 'choice2': 'Он принёс свой обед в школу.',\n",
       " 'question': 'effect',\n",
       " 'label': 0,\n",
       " 'id': 43}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Женщина расточала комплименты подруге.',\n",
       " 'choice1': 'Она хотела попросить подругу об одолжении.',\n",
       " 'choice2': 'Её раздражало нытьё подруги.',\n",
       " 'question': 'cause',\n",
       " 'label': 0,\n",
       " 'id': 56}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Я потянул за собой повозку.',\n",
       " 'choice1': 'Объекты в повозке упали.',\n",
       " 'choice2': 'Колеса повозки повернулись вперёд.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 75}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Я надел резиновые перчатки.',\n",
       " 'choice1': 'Я собрался помыть руки.',\n",
       " 'choice2': 'Я собрался убраться в ванной.',\n",
       " 'question': 'cause',\n",
       " 'label': 1,\n",
       " 'id': 63}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Все в классе уставились на студента.',\n",
       " 'choice1': 'Зазвонил телефон студента.',\n",
       " 'choice2': 'Студент делал записи.',\n",
       " 'question': 'cause',\n",
       " 'label': 0,\n",
       " 'id': 80}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Учитель задал студентам домашнее задание.',\n",
       " 'choice1': 'Студенты сдали записи.',\n",
       " 'choice2': 'Студенты застонали.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 72}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Полиция обыскала машину нарушителя.',\n",
       " 'choice1': 'Они пытались добиться от него признания.',\n",
       " 'choice2': 'Они искали запрещённые препараты.',\n",
       " 'question': 'cause',\n",
       " 'label': 1,\n",
       " 'id': 35}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Мужчина открыл вентиль.',\n",
       " 'choice1': 'Унитаз переполнился водой.',\n",
       " 'choice2': 'Вода потекла из крана.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'premise': 'Секретарь попросил абонента оставаться на линии.',\n",
       " 'choice1': 'Телефон абонента выключился.',\n",
       " 'choice2': 'Абонент терпеливо ждал.',\n",
       " 'question': 'effect',\n",
       " 'label': 1,\n",
       " 'id': 30}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines = read_lines(f'tasks/{task}.jsonl')\n",
    "id_task_items = {\n",
    "    _['id']: _\n",
    "    for _ in parse_jsonl(lines)\n",
    "}\n",
    "\n",
    "for id, task_item in id_task_items.items():\n",
    "    target = id_targets[id]\n",
    "    pred = id_preds[id]\n",
    "    if target == pred:\n",
    "        continue\n",
    "        \n",
    "    display(task_item)\n",
    "    display(target)\n",
    "    display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdc321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-eval",
   "language": "python",
   "name": "rulm-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
