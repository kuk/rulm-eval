{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31e3b479",
   "metadata": {
    "cellId": "sh7t3oq1f1kvir3sh0p5v8"
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines(DOTENV_PATH)\n",
    "pairs = parse_dotenv(lines)\n",
    "os.environ.update(pairs)\n",
    "%run -n main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a48d7",
   "metadata": {
    "cellId": "a33sac1agjgwayk334s5om",
    "heading_collapsed": true
   },
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27fa87",
   "metadata": {
    "cellId": "h8p98um549b4qoyxhs9dd",
    "hidden": true
   },
   "source": [
    "## terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7e758d",
   "metadata": {
    "cellId": "6nqq38gm76nyj64iciwbpa",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {'premise': '\"По словам россиянина, перед ним стояла задача - финишировать впереди \"\"Форс Индии\"\". \"\"Мы начали гонку на покрышках средней жесткости. И я старался отстоять свою позицию на старте, так как все в основном были на мягких шинах\"\".\"',\n",
    "#  'hypothesis': 'Соперники выступали преимущественно на мягких шинах.',\n",
    "#  'label': 'entailment',\n",
    "#  'idx': 104}\n",
    "\n",
    "path = 'data/rsg/TERRa/train.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))\n",
    "\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')\n",
    "    item['target'] = item.pop('label')\n",
    "    \n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['target'] == 'entailment'], 100)\n",
    "    + random.sample([_ for _ in items if _['target'] == 'not_entailment'], 100)\n",
    ")\n",
    "random.shuffle(items)\n",
    "\n",
    "lines = format_jsonl(items[:100])\n",
    "write_lines('tasks/terra/test.jsonl', lines)\n",
    "lines = format_jsonl(items[100:])\n",
    "write_lines('tasks/terra/dev.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a4eda",
   "metadata": {
    "cellId": "102ebj9z0q2fhncvcb1hgl6",
    "hidden": true
   },
   "source": [
    "## danetqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "997227cd",
   "metadata": {
    "cellId": "4t30f2ulbjxud0d8dwj3c",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {'question': 'Есть ли вода на марсе?',\n",
    "#  'passage': 'Гидросфера Марса — это совокупность водных запасов планеты Марс, представленная водным льдом в полярных шапках Марса, льдом над поверхностью, сезонными ручьями из жидкой воды и возможными резервуарами жидкой воды и водных растворов солей в верхних слоях литосферы Марса. Гидросфера ... е шапки Марса, так как предполагалось, что они могут состоять из водного льда по аналогии с Антарктидой или Гренландией на Земле, однако высказывалась и гипотеза, что это твёрдый диоксид углерода.',\n",
    "#  'label': True,\n",
    "\n",
    "path = 'data/rsg/DaNetQA/train.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))\n",
    "\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')\n",
    "    item['target'] = item.pop('label')\n",
    "    \n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['target'] is True], 100)\n",
    "    + random.sample([_ for _ in items if _['target'] is False], 100)\n",
    ")\n",
    "random.shuffle(items)\n",
    "\n",
    "lines = format_jsonl(items[:100])\n",
    "write_lines('tasks/danetqa/test.jsonl', lines)\n",
    "lines = format_jsonl(items[100:])\n",
    "write_lines('tasks/danetqa/dev.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6131ec",
   "metadata": {
    "cellId": "anx770sqn2u8tmbm2odp09",
    "hidden": true
   },
   "source": [
    "## parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53e45592",
   "metadata": {
    "cellId": "ffnrf9fhlor3oesyp41x73",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {'premise': 'Я прибралась дома.',\n",
    "#  'choice1': 'Я была завалена работой.',\n",
    "#  'choice2': 'Я ждала друзей.',\n",
    "#  'question': 'cause',\n",
    "#  'label': 1,\n",
    "#  'id': 96}\n",
    "\n",
    "path = 'data/rsg/PARus/train.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))\n",
    "\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')\n",
    "    item['target'] = item.pop('label')\n",
    "\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['question'] == 'effect'], 100)\n",
    "    + random.sample([_ for _ in items if _['question'] == 'cause'], 100)\n",
    ")\n",
    "random.shuffle(items)\n",
    "\n",
    "lines = format_jsonl(items[:100])\n",
    "write_lines('tasks/parus/test.jsonl', lines)\n",
    "lines = format_jsonl(items[100:])\n",
    "write_lines('tasks/parus/dev.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620407e",
   "metadata": {
    "cellId": "6vhjefkg3padbq3v8ys5lk",
    "hidden": true
   },
   "source": [
    "## rwsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "05055270",
   "metadata": {
    "cellId": "ftjctfz9fnccjqkrp4elwj",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {'text': 'Матери Артура и Селесты пришли в город, чтобы забрать их. Они очень рады, что их вернули, но они также ругают их, потому что они убежали.',\n",
    "#  'target': {'span2_index': 8,\n",
    "#   'span1_index': 0,\n",
    "#   'span1_text': 'Матери',\n",
    "#   'span2_text': 'забрать их'},\n",
    "#  'idx': 190,\n",
    "#  'label': False}\n",
    "\n",
    "path = 'data/rsg/RWSD/train.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))\n",
    "\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')\n",
    "    item['target_'] = item.pop('target')\n",
    "    item['target'] = item.pop('label')\n",
    "    \n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['target'] == True], 100)\n",
    "    + random.sample([_ for _ in items if _['target'] == False], 100)\n",
    ")\n",
    "random.shuffle(items)\n",
    "\n",
    "lines = format_jsonl(items[:100])\n",
    "write_lines('tasks/rwsd/test.jsonl', lines)\n",
    "lines = format_jsonl(items[100:])\n",
    "write_lines('tasks/rwsd/dev.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386c217",
   "metadata": {
    "cellId": "sj6qgu1ql0a99k3bbgwqse",
    "hidden": true
   },
   "source": [
    "## russe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b61bd6c8",
   "metadata": {
    "cellId": "hk27mz8a43wrf5srkvml4",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {'idx': 4107,\n",
    "#  'word': 'защита',\n",
    "#  'sentence1': 'Как изменится защита Динамо в новом сезоне?',\n",
    "#  'sentence2': 'Обе партии протекали на удивление одинаково: в обеих была разыграна..\n",
    "#  'start1': 14,\n",
    "#  'end1': 21,\n",
    "#  'start2': 80,\n",
    "#  'end2': 87,\n",
    "#  'label': True,\n",
    "#  'gold_sense1': 2,\n",
    "#  'gold_sense2': 2}\n",
    "\n",
    "path = 'data/rsg/RUSSE/train.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))\n",
    "\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')\n",
    "    item['target'] = item.pop('label')\n",
    "    \n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['target'] == True], 100)\n",
    "    + random.sample([_ for _ in items if _['target'] == False], 100)\n",
    ")\n",
    "random.shuffle(items)\n",
    "\n",
    "lines = format_jsonl(items[:100])\n",
    "write_lines('tasks/russe/test.jsonl', lines)\n",
    "lines = format_jsonl(items[100:])\n",
    "write_lines('tasks/russe/dev.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614d5ed",
   "metadata": {
    "cellId": "o4a518d0rsz74ijxew2ed",
    "hidden": true
   },
   "source": [
    "## rucola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57ec486c",
   "metadata": {
    "cellId": "len7j4gfvicrafq92urxn",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {'id': '49',\n",
    "#  'sentence': 'Мне бы хотелось открыться кому-нибудь, но разве здесь есть такие люди, которые бы могли меня понять.',\n",
    "#  'acceptable': '1',\n",
    "#  'error_type': '0',\n",
    "#  'detailed_source': 'Seliverstova'}\n",
    "\n",
    "path = 'data/rucola/out_of_domain_dev.csv'\n",
    "items = list(read_csv(path))\n",
    "\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['acceptable'] == '0' and _['error_type'] == 'Hallucination'], 100)\n",
    "    + random.sample([_ for _ in items if _['acceptable'] == '1'], 100)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['target'] = item.pop('acceptable')\n",
    "    \n",
    "\n",
    "lines = format_jsonl(items[:100])\n",
    "write_lines('tasks/rucola/test.jsonl', lines)\n",
    "lines = format_jsonl(items[100:])\n",
    "write_lines('tasks/rucola/dev.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca948b",
   "metadata": {
    "cellId": "bgksjtp820in7r53y17gwf"
   },
   "source": [
    "# eval one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d534c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "model = OPENAI_TURBO\n",
    "task = TERRA\n",
    "test_items, dev_items = load_task(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc3f80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "eval_items = init_eval_items(test_items)\n",
    "\n",
    "for test_item, eval_item in zip(test_items, eval_items):\n",
    "    eval_item['prompt'] = TASK_PROMPT[task](test_item)\n",
    "    \n",
    "for item in eval_items[:2]:\n",
    "    print(item['prompt'])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'evals/{model}/{task}/0-shot.jsonl'\n",
    "lines = read_lines(path)\n",
    "eval_items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb27c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in eval_items if not _.get('output')]\n",
    "# items = rulm_map_complete_eval_items(items, max_workers=6, model='saiga-7b-q4', temperature=0.0)\n",
    "items = openai_map_complete_eval_items(items, max_workers=10, temperature=0)\n",
    "\n",
    "for item in log_progress(items):\n",
    "    print(item['prompt'])\n",
    "    print('---')\n",
    "    print(item['output'])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "for item in eval_items:\n",
    "    output = item['output']\n",
    "    if output:\n",
    "        pred = TASK_OUTPUT_PRED[task](output)\n",
    "        if pred is None:\n",
    "            print(output)\n",
    "            print('---\\n\\n')\n",
    "        item['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_preds = {_['id']: _['pred'] for _ in eval_items}\n",
    "id_targets = {_['id']: _['target'] for _ in test_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b81600",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for item in eval_items:\n",
    "#     if item['output'] and item['pred'] != id_targets[item['id']]:\n",
    "#         print(item['prompt'])\n",
    "#         print('---')\n",
    "#         print(item['output'])\n",
    "#         print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735289bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "correct, support, total = acc_score(id_targets, id_preds)\n",
    "print(correct, support, round(correct / support, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf60859",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(eval_items)\n",
    "path = Path(f'evals/{model}/{task}/0-shot.jsonl')\n",
    "path.parent.mkdir(parents=True, exist_ok=True)\n",
    "write_lines(path, lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a8462",
   "metadata": {},
   "source": [
    "# eval all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "model = SAIGA_13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for task in TASKS:\n",
    "#     path = f'evals/{model}/{task}/0-shot.jsonl'\n",
    "#     lines = read_lines(path)\n",
    "#     items = list(parse_jsonl(lines))\n",
    "    \n",
    "#     for item in items:\n",
    "#         item['output'] = item['pred'] = None\n",
    "#         item.pop('error', None)\n",
    "        \n",
    "#     lines = format_jsonl(items)\n",
    "#     write_lines(path, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for task in TASKS:\n",
    "#     path = f'evals/{model}/{task}/0-shot.jsonl'\n",
    "#     lines = read_lines(path)\n",
    "#     eval_items = list(parse_jsonl(lines))\n",
    "    \n",
    "#     items = [_ for _ in eval_items if not _['output']]\n",
    "#     print(task, len(items))\n",
    "#     results = rulm_map_complete_eval_items(items, max_workers=3, model='saiga-30b-q4', temperature=0.0)\n",
    "#     for _ in log_progress(results, total=len(items)):\n",
    "#         pass\n",
    "\n",
    "#     lines = format_jsonl(eval_items)\n",
    "#     write_lines(path, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "for task in TASKS:\n",
    "    path = f'evals/{model}/{task}/0-shot.jsonl'\n",
    "    lines = read_lines(path)\n",
    "    eval_items = list(parse_jsonl(lines))\n",
    "    \n",
    "    for item in eval_items:\n",
    "        if item['output']:\n",
    "            item['pred'] = TASK_OUTPUT_PRED[task](item['output'])\n",
    "            \n",
    "    print(task, sum(_['pred'] is not None for _ in eval_items))\n",
    "\n",
    "    lines = format_jsonl(eval_items)\n",
    "    write_lines(path, lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8e5a2",
   "metadata": {},
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4005ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task</th>\n",
       "      <th>terra</th>\n",
       "      <th>danetqa</th>\n",
       "      <th>parus</th>\n",
       "      <th>rwsd</th>\n",
       "      <th>russe</th>\n",
       "      <th>rucola</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sota</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai_turbo</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93, 1!</td>\n",
       "      <td>0.94, 11!</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73, 2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saiga_7b</th>\n",
       "      <td>0.55, 1!</td>\n",
       "      <td>0.87, 1!</td>\n",
       "      <td>0.54, 13!</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58, 2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saiga_13b</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54, 5!</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52, 7!</td>\n",
       "      <td>0.50, 10!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saiga_30b</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.85, 67!</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task             terra   danetqa      parus   rwsd     russe     rucola\n",
       "model                                                                  \n",
       "human             0.92     0.915      0.982   0.84     0.805       0.84\n",
       "sota             0.877     0.917      0.908  0.675     0.823       0.82\n",
       "openai_turbo      0.90  0.93, 1!  0.94, 11!   0.48      0.62   0.73, 2!\n",
       "saiga_7b      0.55, 1!  0.87, 1!  0.54, 13!   0.55      0.45   0.58, 2!\n",
       "saiga_13b         0.68      0.59   0.54, 5!   0.55  0.52, 7!  0.50, 10!\n",
       "saiga_30b         0.56      0.59  0.85, 67!   0.55      0.52       0.55"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -n main.py\n",
    "data = []\n",
    "for model in MODELS:\n",
    "    for task in TASKS:\n",
    "        path = f'tasks/{task}/test.jsonl'\n",
    "        lines = read_lines(path)\n",
    "        task_items = list(parse_jsonl(lines))\n",
    "        \n",
    "        path = f'evals/{model}/{task}/0-shot.jsonl'\n",
    "        lines = read_lines(path)\n",
    "        eval_items = list(parse_jsonl(lines))\n",
    "        \n",
    "        id_targets = {_['id']: _['target'] for _ in task_items}\n",
    "        id_preds = {_['id']: _['pred'] for _ in eval_items}\n",
    "        \n",
    "        correct, support, total = acc_score(id_targets, id_preds)\n",
    "        if not total:\n",
    "            continue\n",
    "        acc = correct / support\n",
    "        \n",
    "        data.append([model, task, acc, support, total])\n",
    "\n",
    "rows = []        \n",
    "for model, task, acc, support, total in data:\n",
    "    value = '%.2f' % acc\n",
    "    undef = total - support\n",
    "    if undef:\n",
    "        value += ', %d!' % undef\n",
    "\n",
    "    rows.append((model, task, value))\n",
    "\n",
    "for task, score in rsg_lb_human(RSG_LB):\n",
    "    rows.append(('human', task, score))\n",
    "\n",
    "for task, score in rsg_lb_sota(RSG_LB):\n",
    "    rows.append(('sota', task, score))\n",
    "\n",
    "rows.append(('human', RUCOLA, RUCOLA_LB_HUMAN))\n",
    "rows.append(('sota', RUCOLA, RUCOLA_LB_SOTA))\n",
    "\n",
    "table = pd.DataFrame(rows, columns=['model', 'task', 'score'])\n",
    "table = table.pivot(index='model', columns='task', values='score')\n",
    "table = table.fillna('-')\n",
    "table = table.reindex(\n",
    "    columns=TASKS,\n",
    "    index=['human', 'sota'] + MODELS\n",
    ")\n",
    "table \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f1add",
   "metadata": {},
   "source": [
    "# evals view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9fb4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "task_samples = {}\n",
    "for task in TASKS:\n",
    "    path = f'tasks/{task}/test.jsonl'\n",
    "    lines = read_lines(path)\n",
    "    items = parse_jsonl(lines)\n",
    "    id_targets = {_['id']: _['target'] for _ in items}\n",
    "\n",
    "    id_model_items = defaultdict(dict)\n",
    "    for model in MODELS:\n",
    "        path = f'evals/{model}/{task}/0-shot.jsonl'\n",
    "        lines = read_lines(path)\n",
    "        items = parse_jsonl(lines)\n",
    "        for item in items:\n",
    "            id_model_items[item['id']][model] = item\n",
    "\n",
    "    ids = random.sample(list(id_model_items), 5)\n",
    "    samples = []\n",
    "    for id in ids:\n",
    "        target = id_targets[id]\n",
    "        model_items = id_model_items[id]\n",
    "        prompt = model_items[MODELS[0]]['prompt']\n",
    "        for model, eval_item in model_items.items():\n",
    "            assert prompt == eval_item['prompt']\n",
    "\n",
    "        samples.append({\n",
    "            'id': id,\n",
    "            'prompt': prompt,\n",
    "            'target': target,\n",
    "            'model_items': model_items\n",
    "        })\n",
    "    task_samples[task] = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a89b9573",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>terra</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>#125</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение. Ответь \"да\" или \"нет.\n",
      "\n",
      "Текст: Президент напомнил, что апеллировать при этом необходимо к Государственной Думе, потому что амнистию объявляет парламент, а не президент.\n",
      "Утверждение: Президент напомнил, кто объявляет амнистию.\n",
      "Верно: \n",
      "target\tentailment\n",
      "\n",
      "openai_turbo\tentailment\tДа.\n",
      "saiga_7b\tentailment\tДа.\n",
      "saiga_13b\tentailment\tДа.\n",
      "saiga_30b\tentailment\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#1188</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение. Ответь \"да\" или \"нет.\n",
      "\n",
      "Текст: За рулем находилась женщина, которая не уступила дорогу мальчику.\n",
      "Утверждение: За рулем никого не было.\n",
      "Верно: \n",
      "target\tnot_entailment\n",
      "\n",
      "openai_turbo\tnot_entailment\tНет.\n",
      "saiga_7b\tentailment\tДа.\n",
      "saiga_13b\tnot_entailment\tНет.\n",
      "saiga_30b\tentailment\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#2243</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение. Ответь \"да\" или \"нет.\n",
      "\n",
      "Текст: Девушка работала в павильоне торгового центра, где продавала косметику и парфюмерию.\n",
      "Утверждение: Девушка работала продавщицей.\n",
      "Верно: \n",
      "target\tentailment\n",
      "\n",
      "openai_turbo\tentailment\tДа.\n",
      "saiga_7b\tentailment\tДа.\n",
      "saiga_13b\tentailment\tДа.\n",
      "saiga_30b\tentailment\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#1499</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение. Ответь \"да\" или \"нет.\n",
      "\n",
      "Текст: \"Мне представляется, что нельзя людей держать за быдло, а надо постоянно работать таким образом, чтобы люди имели возможность выбирать. Чтобы радиостанция предоставляла им возможность выбора. Потому что \"\"Эхо\"\" - это отражение страны.\"\n",
      "Утверждение: Я думаю, что держать людей за быдло нельзя.\n",
      "Верно: \n",
      "target\tentailment\n",
      "\n",
      "openai_turbo\tentailment\tДа.\n",
      "saiga_7b\tentailment\tДа.\n",
      "saiga_13b\tentailment\tВыходные данные: Да.\n",
      "saiga_30b\tentailment\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#2405</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст, проверь верно ли утверждение. Ответь \"да\" или \"нет.\n",
      "\n",
      "Текст: В ходе разбирательств выяснилось, что данное транспортное средство числится в угоне.\n",
      "Утверждение: Оказалось, что самолет угнан.\n",
      "Верно: \n",
      "target\tnot_entailment\n",
      "\n",
      "openai_turbo\tentailment\tДа.\n",
      "saiga_7b\tentailment\tДа.\n",
      "saiga_13b\tentailment\tДа.\n",
      "saiga_30b\tentailment\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>danetqa</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>#690</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос. Ответь коротко \"да\" или \"нет\".\n",
      "\n",
      "Текст: «Ведьмак 3: Дикая Охота»  — мультиплатформенная компьютерная игра в жанре action/RPG, разработанная польской студией CD Projekt RED по мотивам серии романов «Ведьмак» польского писателя Анджея Сапковского, выпущенная в 2015 году для Windows, PlayStation 4 и Xbox One. Игра является продолжением компьютерных игр «Ведьмак» и «Ведьмак 2: Убийцы королей», заключительной частью трилогии. Действие игры происходит в вымышленном фэнтезийном мире, основанном на славянской мифологии. Главный герой Геральт из Ривии, «ведьмак» — профессиональный охотник на чудовищ — отправляется в путешествие в поисках девушки по имени Цири, обладающей сверхъестественными способностями. В отличие от предыдущих игр серии, «Ведьмак 3: Дикая Охота» — игра с открытым миром: игрок может свободно путешествовать по обширным территориям, самостоятельно находя новые места и задания.\n",
      "Вопрос: Был ли геральт в дикой охоте?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа, Геральт был в дикой охоте.\n",
      "saiga_13b\tTrue\tДа. Геральт был в дикой охоте.\n",
      "saiga_30b\tTrue\tДа. Геральт участвовал в дикой охоте на чудовищ в игре \"Ведьмак 3: Дикая Охота\".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#55</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос. Ответь коротко \"да\" или \"нет\".\n",
      "\n",
      "Текст: Через месяц Ивану Тимофеевичу приходит время возвращаться в город. Он предлагает Олесе выйти за него и уехать вместе, но Олеся отказывается, объясняя это тем, что не может венчаться в церкви, так как она колдунья, а значит, принадлежит дьяволу. На следующий день молодой барин уезжает в соседнее село. Вернувшись после обеда, он встречает приказчика Никиту Назарыча Мищенку, который рассказывает, что у церкви крестьяне поймали и избили ведьму. Она выскользнула из толпы и убежала в лес, крича проклятья.\n",
      "Вопрос: Были ли олеся и ее бабка колдуньями?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tTrue\tДа (Олеся была колдуньей, не уточняется про ее бабку).\n",
      "saiga_7b\tFalse\tНет, Олеся и ее бабка не были колдуньями. Они были просто людьми, которые не принадлежали к церкви и не были связаны с дьяволом.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#677</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос. Ответь коротко \"да\" или \"нет\".\n",
      "\n",
      "Текст: Нил Олден Армстронг  — американский астронавт НАСА, лётчик-испытатель, космический инженер, профессор университета, военно-морской лётчик США, первый человек, ступивший на Луну 20 июля 1969 года в ходе лунной экспедиции корабля «Аполлон-11». Родился 5 августа 1930 года в городе Уапаконета  в семье Стивена Армстронга  и Виолы Энгель . Имел шотландско-ирландское и немецкое происхождение. В семье воспитывалась также младшая сестра Джун  и младший брат Дин . Отец работал аудитором на правительство штата, и после рождения семья часто переезжала из города в город: они успели пожить в двадцати различных городах до того, как окончательно осели в Уапаконете  в 1944 году.\n",
      "Вопрос: Был ли нил армстронг на луне?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа, Нил Армстронг был на Луне.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#383</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос. Ответь коротко \"да\" или \"нет\".\n",
      "\n",
      "Текст: Английская революция, известная также как Английская гражданская война ; в советской историографии именовалась Английская буржуазная революция — происходивший в 1640—1660 годах процесс перехода Англии от монархии к буржуазной республике, закончившийся смертью протектора Кромвеля и реставрацией монархии. Революция приняла форму конфликта исполнительной и законодательной властей , вылившегося в гражданскую войну, а также религиозной войны между англиканами, католиками и колеблющимися шотландскими пуританами с одной стороны, и английскими пуританами с другой. В Английской революции был заметен, хотя играл и второстепенную роль, также элемент национальной борьбы . Первая гражданская война началась 22 августа 1642 г., когда Карл I приказал поднять своё знамя над Ноттингемским замком, а закончилась война в 1646 г., когда Кромвель создал «Армию нового образца», одержавшую решающую победу в сражении при Несби. Гражданская война завершилась полной победой парламента.\n",
      "Вопрос: Была ли в англии революция?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа, в Англии произошла революция.\n",
      "saiga_13b\tTrue\tДа. Английская революция была в Англии.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#523</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос. Ответь коротко \"да\" или \"нет\".\n",
      "\n",
      "Текст: Средняя температура стратомезосферы исключительно низкая и составляет -133°С. В отличие от Земли, где в стратосфере содержится преимущественно весь атмосферный озон, на Марсе его концентрация ничтожно мала . Выше стратомезосферы простирается верхний слой атмосферы — термосфера. Для нее свойственен рост температуры с высотой до максимального значения , после чего она остаётся постоянной до верхней границы . В этом слое зарегистрировано присутствие атомарного кислорода; его плотность на высоте 200 км достигает 5—6⋅107 см−3.\n",
      "Вопрос: Есть ли атмосфера на марсе?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа, на Марсе есть атмосфера.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>parus</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>#258</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про причинно-следственную связь. Выбери вариант ответа A или B\n",
      "\n",
      "Текст: Знаменитость носила очки.\n",
      "Вопрос: Что было причиной?\n",
      "A. Она хотела поблагодарить своих поклонников.\n",
      "B. Она хотела, чтобы её не узнали.\n",
      "Ответ: \n",
      "target\t1\n",
      "\n",
      "openai_turbo\t1\tB. Она хотела, чтобы её не узнали.\n",
      "saiga_7b\t0\tВыбор: A. Она хотела поблагодарить своих поклонников.\n",
      "saiga_13b\t0\tВыбор варианта ответа: A.\n",
      "saiga_30b\tNone\tВыбор ответа зависит от контекста и цели задания. Если задание предполагает выяснение причинно-следственной связи, то ответ должен быть основан на данных, которые были предоставлены в тексте. В данном случае, ответ должен быть \"Б\".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#30</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про причинно-следственную связь. Выбери вариант ответа A или B\n",
      "\n",
      "Текст: Женщина напевала про себя.\n",
      "Вопрос: Что было причиной?\n",
      "A. Она нервничала.\n",
      "B. Она была в хорошем настроении.\n",
      "Ответ: \n",
      "target\t1\n",
      "\n",
      "openai_turbo\t1\tB. Она была в хорошем настроении.\n",
      "saiga_7b\t0\tВыбор: A. Она нервничала.\n",
      "saiga_13b\t0\tВыбор варианта ответа: A.\n",
      "saiga_30b\tNone\tВыбор ответа зависит от контекста и дополнительной информации. Если женщина напевала про себя, то это может быть как следствие нервности, так и следствие хорошего настроения. Если же есть дополнительная информация, то можно выбрать один из вариантов.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#280</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про причинно-следственную связь. Выбери вариант ответа A или B\n",
      "\n",
      "Текст: Покупатель хотел узнать цену товара.\n",
      "Вопрос: Что случилось в результате?\n",
      "A. Он проверил ценник.\n",
      "B. Он решил купить товар.\n",
      "Ответ: \n",
      "target\t0\n",
      "\n",
      "openai_turbo\t0\tA. Он проверил ценник.\n",
      "saiga_7b\t0\tВыбор A.\n",
      "saiga_13b\t1\tВыбор: B\n",
      "saiga_30b\t0\tВыходные данные: A. Он проверил ценник.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#284</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про причинно-следственную связь. Выбери вариант ответа A или B\n",
      "\n",
      "Текст: Девочка нашла сериал скучным.\n",
      "Вопрос: Что случилось в результате?\n",
      "A. Она записала его.\n",
      "B. Она выключила его.\n",
      "Ответ: \n",
      "target\t1\n",
      "\n",
      "openai_turbo\t1\tB. Она выключила его.\n",
      "saiga_7b\tNone\tВыбор A или B зависит от того, какое действие девочка решила предпринять. Если она решила записать сериал, то ответ будет \"Она записала его\". Если же она решила выключить сериал, то ответ будет \"Она выключила его\".\n",
      "saiga_13b\t1\tВыходные данные: B\n",
      "saiga_30b\t1\tВыходные данные: B. Она выключила его.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#43</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про причинно-следственную связь. Выбери вариант ответа A или B\n",
      "\n",
      "Текст: В его глаза попала инфекция.\n",
      "Вопрос: Что случилось в результате?\n",
      "A. Он ослеп.\n",
      "B. Он надел очки.\n",
      "Ответ: \n",
      "target\t0\n",
      "\n",
      "openai_turbo\t0\tA. Он ослеп.\n",
      "saiga_7b\t0\tВыбор: A. Он ослеп.\n",
      "\n",
      "Решение:\n",
      "\n",
      "Выбор A.\n",
      "\n",
      "Причина:\n",
      "\n",
      "Выбор A.\n",
      "\n",
      "Следствие:\n",
      "\n",
      "Выбор A.\n",
      "\n",
      "Причинно-следственная связь:\n",
      "\n",
      "Выбор A.\n",
      "saiga_13b\t0\tВыбор варианта ответа: A.\n",
      "saiga_30b\t0\tОтвет: A. Он ослеп.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>rwsd</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>#211</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос про кореференцию. Ответь \"да\" или \"нет\".\n",
      "\n",
      "Текст: Мужчина зашел в банк и разбил голову одному из клерков. Его немедленно забрала скорая.\n",
      "Вопрос: Фраза \"Его\" ссылается на \"клерков\"?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tFalse\tНет.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#506</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос про кореференцию. Ответь \"да\" или \"нет\".\n",
      "\n",
      "Текст: Джордж отдал бесплатные билеты на спектакль Эрику, потому что ему особенно хотелось посмотреть постановку.\n",
      "Вопрос: Фраза \"ему особенно хотелось\" ссылается на \"Джордж\"?\n",
      "Ответ: \n",
      "target\tFalse\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#272</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос про кореференцию. Ответь \"да\" или \"нет\".\n",
      "\n",
      "Текст: Шоссе к озеру было перекрыто, так что мы не могли по нему проехать.\n",
      "Вопрос: Фраза \"по нему проехать\" ссылается на \"Шоссе\"?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#436</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос про кореференцию. Ответь \"да\" или \"нет\".\n",
      "\n",
      "Текст: Дэн занял переднее место, а Билл – заднее, потому что его окрик \"чур я спереди\" прозвучал раньше.\n",
      "Вопрос: Фраза \"его\" ссылается на \"Дэн\"?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tFalse\tНет.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#566</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитай текст и ответь на вопрос про кореференцию. Ответь \"да\" или \"нет\".\n",
      "\n",
      "Текст: Пользователь сменил свой пароль с \"Grwqwu8jyc\" на \"серобуромалиновый синхрофазотрон\". Так ведь и забыть можно!\n",
      "Вопрос: Фраза \"Так\" ссылается на \"Grwqwu8jyc\"?\n",
      "Ответ: \n",
      "target\tTrue\n",
      "\n",
      "openai_turbo\tFalse\tНет.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>russe</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>#16064</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про значение слова в контексте. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "A: Работа над диском шла три года, и результат действительно неплохой\n",
      "B: Патроны в диске кончились. Солдат все давил и давил на спуск, не переставая кричать и подпрыгивать\n",
      "Вопрос: Слово \"диск\" имеет одинаковое значение в A и B?\n",
      "Ответ: \n",
      "target\tFalse\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа, слово \"диск\" имеет одинаковое значение в A и B.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#12440</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про значение слова в контексте. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "A: Дополнительные материалы к журналу – на приложенном диске\n",
      "B: Прохождение Венеры по солнечному диску\n",
      "Вопрос: Слово \"диск\" имеет одинаковое значение в A и B?\n",
      "Ответ: \n",
      "target\tFalse\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#9420</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про значение слова в контексте. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "A: Также не должно изображать святых жен и дев с опущенными книзу глазами: дева начинает тогда опускать вниз глаза, когда явится в ней ощущение греховное; в невинности своей она глядит прямо\n",
      "B: Зачастую отец испытывает настоящую жгучую ревность к крошечному существу, которое якобы сумело вытеснить его из сердца жены\n",
      "Вопрос: Слово \"жена\" имеет одинаковое значение в A и B?\n",
      "Ответ: \n",
      "target\tFalse\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tFalse\tНет. В A и B слова \"жена\" имеют разное значение. В A это слово используется для описания святой, а в B это слово используется для описания отеца.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#5294</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про значение слова в контексте. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "A: А внизу перед алтарем лежит большой камень с жилками красноватого или кровяного цвета\n",
      "B: Кроме простодушного вида надо было иметь еще деловую жилку и море обаяния\n",
      "Вопрос: Слово \"жилка\" имеет одинаковое значение в A и B?\n",
      "Ответ: \n",
      "target\tFalse\n",
      "\n",
      "openai_turbo\tFalse\tНет.\n",
      "saiga_7b\tTrue\tДа.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#3757</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос про значение слова в контексте. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "A: Доброе дело\n",
      "B: Я ему объяснила, он понял и даже не рассердился, воспринял это как дело житейское\n",
      "Вопрос: Слово \"дело\" имеет одинаковое значение в A и B?\n",
      "Ответ: \n",
      "target\tFalse\n",
      "\n",
      "openai_turbo\tTrue\tДа.\n",
      "saiga_7b\tTrue\tДа, в A и B слова \"дело\" имеют одинаковое значение.\n",
      "saiga_13b\tTrue\tДа.\n",
      "saiga_30b\tTrue\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>rucola</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>#463</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение корректное или нет? Проверь синтаксис, семантику и морфологию. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "Предложение: Уэйн подтвердил подписку с YoungMoney последним артистом, который заключил контракт на свою сцену.\n",
      "Корректное: \n",
      "target\t0\n",
      "\n",
      "openai_turbo\t1\tДа.\n",
      "saiga_7b\t1\tДа.\n",
      "saiga_13b\t1\tДа.\n",
      "saiga_30b\t1\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#201</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение корректное или нет? Проверь синтаксис, семантику и морфологию. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "Предложение: Ответственность за продукцию: Рекреационное и спортивное оборудование.\n",
      "Корректное: \n",
      "target\t1\n",
      "\n",
      "openai_turbo\t1\tДа.\n",
      "saiga_7b\t1\tДа.\n",
      "saiga_13b\t1\tДа.\n",
      "saiga_30b\t1\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#720</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение корректное или нет? Проверь синтаксис, семантику и морфологию. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "Предложение: Какой персонаж в брачных играх должен стоять возле своей соперницы, преследуя неудачников.\n",
      "Корректное: \n",
      "target\t1\n",
      "\n",
      "openai_turbo\t0\tНет.\n",
      "saiga_7b\t1\tДа.\n",
      "saiga_13b\t1\tДа.\n",
      "saiga_30b\t1\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#1600</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение корректное или нет? Проверь синтаксис, семантику и морфологию. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "Предложение: Время спустя у меня была дата хирургического вмешательства всего несколько недель назад, и большой жирный рецепт для перкоцета.\n",
      "Корректное: \n",
      "target\t0\n",
      "\n",
      "openai_turbo\tNone\tNone\n",
      "saiga_7b\t1\tДа.\n",
      "saiga_13b\t1\tДа.\n",
      "saiga_30b\t1\tДа.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>#357</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение корректное или нет? Проверь синтаксис, семантику и морфологию. Ответь коротко: \"да\" или \"нет\".\n",
      "\n",
      "Предложение: Грядки в первой части были пригодны к сбору живого материала летом.\n",
      "Корректное: \n",
      "target\t1\n",
      "\n",
      "openai_turbo\t1\tда\n",
      "saiga_7b\t1\tДа.\n",
      "saiga_13b\t1\tДа.\n",
      "saiga_30b\t1\tДа.\n"
     ]
    }
   ],
   "source": [
    "%run -n main.py\n",
    "for task in TASKS:\n",
    "    show_html(f'<h3>{task}</h3>')\n",
    "    samples = task_samples[task]\n",
    "    \n",
    "    for sample in samples:\n",
    "        show_html(f'<h4>#{sample[\"id\"]}</h4>')\n",
    "\n",
    "        print(sample['prompt'])\n",
    "        print('target', sample['target'], sep='\\t')\n",
    "        print()\n",
    "\n",
    "        for model in MODELS:\n",
    "            item = sample['model_items'][model]\n",
    "            print(model, item['pred'], item['output'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e84e31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('evals/view.md', 'w') as file:\n",
    "    for task in TASKS:\n",
    "        print(f'<h2>{task}</h2>', file=file)\n",
    "        samples = task_samples[task]\n",
    "    \n",
    "        for sample in samples:\n",
    "            print(f'<h4>#{sample[\"id\"]}</h4>', file=file)\n",
    "            prompt = sample['prompt'].replace('\\n', '<br/>')\n",
    "            print(f'''\n",
    "{prompt}\n",
    "<br/>\n",
    "''', file=file)\n",
    "            print('<table>', file=file)\n",
    "            print(f'''\n",
    "<tr>\n",
    "<td>target</td>\n",
    "<td>{sample[\"target\"]}</td>\n",
    "</tr>\n",
    "''', file=file)\n",
    "            for model in MODELS:\n",
    "                print('<tr>', file=file)\n",
    "                item = sample['model_items'][model]\n",
    "                print(f'''\n",
    "<td>{model}</td>\n",
    "<td>{item[\"pred\"]}</td>\n",
    "<td>{item[\"output\"]}</td>\n",
    "''', file=file)\n",
    "                print('</tr>', file=file)\n",
    "            print('</table>', file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79700af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-sbs",
   "language": "python",
   "name": "rulm-sbs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "notebookId": "c17751d3-4b57-40b0-b19b-01f455662e3c",
  "notebookPath": "rulm-eval/main.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
