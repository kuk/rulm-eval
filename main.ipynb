{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines(DOTENV_PATH)\n",
    "pairs = parse_dotenv(lines)\n",
    "os.environ.update(pairs)\n",
    "%run -n main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2b66c",
   "metadata": {},
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc2f6",
   "metadata": {},
   "source": [
    "## terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ac4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/rsg/TERRa/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32279ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['label'] == 'entailment'], 50)\n",
    "    + random.sample([_ for _ in items if _['label'] == 'not_entailment'], 50)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/terra.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be69595",
   "metadata": {},
   "source": [
    "## danetqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/rsg/DaNetQA/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['label'] is True], 50)\n",
    "    + random.sample([_ for _ in items if _['label'] is False], 50)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/danetqa.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785817db",
   "metadata": {},
   "source": [
    "## parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/rsg/PARus/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a28918",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['question'] == 'effect'], 48)\n",
    "    + random.sample([_ for _ in items if _['question'] == 'cause'], 52)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/parus.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54ac4c",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a8022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines('tasks/parus.jsonl')\n",
    "task_items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72406cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_ids = {}\n",
    "lines = read_lines('evals/03_openai_parus.jsonl')\n",
    "items = parse_jsonl(lines)\n",
    "cache_ids = {_['id'] for _ in items}\n",
    "len(cache_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939797e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "for task_item in log_progress([_ for _ in task_items if _['id'] not in cache_ids]):\n",
    "    prompt = parus_prompt(task_item)\n",
    "    response = join_tokens(openai_generate_stream(prompt, model=TEXT_DAVINCHI_003))\n",
    "    eval_items.append({\n",
    "        'id': task_item['id'],\n",
    "        'response': response\n",
    "    })\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9dcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0131bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[_['label'] for _ in task_items[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910137d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(eval_items)\n",
    "write_lines('evals/03_openai_parus.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0e5a5",
   "metadata": {},
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "model_task_evals = [\n",
    "    (TEXT_DAVINCHI_003, TERRA, '01_openai_terra'),\n",
    "    (TEXT_DAVINCHI_003, DANETQA, '02_openai_danetqa'),\n",
    "    (TEXT_DAVINCHI_003, PARUS, '03_openai_parus'),\n",
    "]\n",
    "data = []\n",
    "for model, task, eval in model_task_evals:\n",
    "    lines = read_lines(f'tasks/{task}.jsonl')\n",
    "    id_targets = {\n",
    "        _['id']: _['label']\n",
    "        for _ in parse_jsonl(lines)\n",
    "    }\n",
    "    \n",
    "    lines = read_lines(f'evals/{eval}.jsonl')\n",
    "    norm_response = NORM_RESPONSE[task]\n",
    "    id_preds = {\n",
    "        _['id']: norm_response(_['response'])\n",
    "        for _ in parse_jsonl(lines)\n",
    "    }\n",
    "    score = acc_score(id_targets, id_preds)\n",
    "    data.append((model, task, score))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226b29a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b7cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-eval",
   "language": "python",
   "name": "rulm-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
