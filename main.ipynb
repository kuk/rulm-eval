{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6c78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines(DOTENV_PATH)\n",
    "pairs = parse_dotenv(lines)\n",
    "os.environ.update(pairs)\n",
    "%run -n main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2b66c",
   "metadata": {},
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc2f6",
   "metadata": {},
   "source": [
    "## terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ac4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/rsg/TERRa/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32279ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['label'] == 'entailment'], 50)\n",
    "    + random.sample([_ for _ in items if _['label'] == 'not_entailment'], 50)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/terra.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be69595",
   "metadata": {},
   "source": [
    "## danetqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/rsg/DaNetQA/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['label'] is True], 50)\n",
    "    + random.sample([_ for _ in items if _['label'] is False], 50)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeec6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/danetqa.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4648e",
   "metadata": {},
   "source": [
    "## parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c713b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/rsg/PARus/val.jsonl'\n",
    "lines = read_lines(path)\n",
    "items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "items = (\n",
    "    random.sample([_ for _ in items if _['question'] == 'effect'], 48)\n",
    "    + random.sample([_ for _ in items if _['question'] == 'cause'], 52)\n",
    ")\n",
    "random.shuffle(items)\n",
    "for item in items:\n",
    "    item['id'] = item.pop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60173df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(items)\n",
    "write_lines('tasks/parus.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54ac4c",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c185bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TERRA\n",
    "eval = '07_code_cushman_terra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "976a8022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "lines = read_lines(f'tasks/{task}.jsonl')\n",
    "task_items = list(parse_jsonl(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "72406cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(f'evals/{eval}.jsonl')\n",
    "eval_items = []\n",
    "if path.exists():\n",
    "    lines = read_lines(path)\n",
    "    eval_items.extend(parse_jsonl(lines))\n",
    "len(eval_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19d3a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "%run -n main.py\n",
    "cache_ids = {_['id'] for _ in eval_items}\n",
    "nocache_task_items = [_ for _ in task_items if _['id'] not in cache_ids]\n",
    "\n",
    "for task_item in log_progress(nocache_task_items):\n",
    "    prompt = TASK_PROMPTS[task](task_item)\n",
    "    response = join_tokens(openai_completions_stream(prompt, model=CODE_CUSHMAN_001))\n",
    "    eval_items.append({\n",
    "        'id': task_item['id'],\n",
    "        'response': response\n",
    "    })\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "85fdfabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 131, 'response': 'No'},\n",
       " {'id': 72, 'response': 'Yes'},\n",
       " {'id': 167, 'response': 'No'}]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "993927e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entailment',\n",
       " 'not_entailment',\n",
       " 'entailment',\n",
       " 'entailment',\n",
       " 'entailment',\n",
       " 'not_entailment',\n",
       " 'not_entailment',\n",
       " 'not_entailment',\n",
       " 'not_entailment',\n",
       " 'entailment']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_['label'] for _ in task_items[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "910137d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = format_jsonl(eval_items)\n",
    "write_lines(f'evals/{eval}.jsonl', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0e5a5",
   "metadata": {},
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fa659c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text-davinci-003', 'terra', (0.91, 0)),\n",
       " ('text-davinci-003', 'danetqa', (0.79, 0)),\n",
       " ('text-davinci-003', 'parus', (0.93, 0)),\n",
       " ('gpt-3.5-turbo-0301', 'parus', (0.9130434782608695, 8)),\n",
       " ('gpt-3.5-turbo-0301', 'danetqa', (0.8350515463917526, 3)),\n",
       " ('gpt-3.5-turbo-0301', 'terra', (0.86, 0))]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -n main.py\n",
    "model_task_evals = [\n",
    "    (TEXT_DAVINCHI_003, TERRA, '01_davinci_terra'),\n",
    "    (TEXT_DAVINCHI_003, DANETQA, '02_davinci_danetqa'),\n",
    "    (TEXT_DAVINCHI_003, PARUS, '03_davinci_parus'),\n",
    "    (GPT_35_TURBO_0301, PARUS, '04_turbo_parus'),\n",
    "    (GPT_35_TURBO_0301, DANETQA, '05_turbo_danetqa'),\n",
    "    (GPT_35_TURBO_0301, TERRA, '06_turbo_terra'),\n",
    "]\n",
    "data = []\n",
    "for model, task, eval in model_task_evals:\n",
    "    lines = read_lines(f'tasks/{task}.jsonl')\n",
    "    id_targets = {\n",
    "        _['id']: _['label']\n",
    "        for _ in parse_jsonl(lines)\n",
    "    }\n",
    "    \n",
    "    lines = read_lines(f'evals/{eval}.jsonl')\n",
    "    norm_response = NORM_RESPONSES[task]\n",
    "    id_preds = {\n",
    "        _['id']: norm_response(_['response'])\n",
    "        for _ in parse_jsonl(lines)\n",
    "    }\n",
    "    score = acc_score(id_targets, id_preds)\n",
    "    data.append((model, task, score))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9711ce",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "73674966",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lines = read_lines(f'tasks/{task}.jsonl')\n",
    "# id_task_items = {\n",
    "#     _['id']: _\n",
    "#     for _ in parse_jsonl(lines)\n",
    "# }\n",
    "\n",
    "# for id, task_item in id_task_items.items():\n",
    "#     target = id_targets[id]\n",
    "#     pred = id_preds[id]\n",
    "#     if target == pred:\n",
    "#         continue\n",
    "        \n",
    "#     display(task_item)\n",
    "#     display(target)\n",
    "#     display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752bb7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-eval",
   "language": "python",
   "name": "rulm-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
